import streamlit as st
from video_card import video_card
from card import card

# ================== PAGE: MACHINE LEARNING ==================
def machine_learning_page():
    st.title("ğŸ¤– Machine Learning â€“ Lá»™ trÃ¬nh tá»« cÆ¡ báº£n Ä‘áº¿n nÃ¢ng cao")
    st.info("Tá»« thuáº­t toÃ¡n cÆ¡ báº£n Ä‘áº¿n á»©ng dá»¥ng thá»±c táº¿ trong dá»± Ã¡n ML")

    # ================== CHÆ¯Æ NG 1 ==================
    st.markdown("---")
    st.header("ğŸš€ ChÆ°Æ¡ng 1: Nháº­p MÃ´n Machine Learning")
    st.info("ğŸ¯ Má»¥c tiÃªu: Hiá»ƒu báº£n cháº¥t ML, thuáº­t toÃ¡n cÆ¡ báº£n, cÃ¡ch Ä‘Ã¡nh giÃ¡ vÃ  tá»‘i Æ°u mÃ´ hÃ¬nh")

    with st.expander("Xem chi tiáº¿t: "):
        # BÃ i há»c
        col1, _, col2 = st.columns([8, 1, 8])
        with col1:
            card("BÃ i 1: Machine Learning lÃ  gÃ¬?",
                 "PhÃ¢n biá»‡t AI, ML, DL. Supervised vs Unsupervised vs Reinforcement. Workflow ML: Data â†’ Feature â†’ Model â†’ Evaluation â†’ Deploy.",
                 icon="ğŸ“‘",
                 color='#e8f5e9'
                 )
            card("BÃ i 2: Há»“i quy tuyáº¿n tÃ­nh (Linear Regression)",
                 "CÃ´ng thá»©c y = wx + b. TÃ¬m w, b tá»‘i Æ°u báº±ng Least Squares. Thá»±c hÃ nh vá»›i scikit-learn: fit(), predict(), score().",
                 icon="ğŸ“‘",
                 color='#e8f5e9'
                 )
            card("BÃ i 3: Há»“i quy logistic (Logistic Regression)",
                 "Sigmoid function cho phÃ¢n loáº¡i nhá»‹ phÃ¢n. Probability vs Binary prediction. Thá»±c hÃ nh phÃ¢n loáº¡i khÃ¡ch hÃ ng mua/khÃ´ng mua.",
                 icon="ğŸ“‘",
                 color='#e8f5e9'
                 )
            card("BÃ i 4: Loss Functions",
                 "MSE cho regression, Cross-Entropy cho classification. Hiá»ƒu táº¡i sao chá»n loss function phÃ¹ há»£p vá»›i tá»«ng bÃ i toÃ¡n.",
                 icon="ğŸ“‘",
                 color='#e8f5e9'
                 )
        with col2:
            card("BÃ i 5: Gradient Descent chuyÃªn sÃ¢u",
                 "CÃ¡ch thuáº­t toÃ¡n 'há»c' báº±ng cÃ¡ch giáº£m loss. Learning rate, epoch, batch size. Stochastic vs Mini-batch vs Full-batch GD.",
                 icon="ğŸ“‘",
                 color='#e8f5e9'
                 )
            card("BÃ i 6: Train/Validation/Test Split",
                 "Táº¡i sao cáº§n chia dá»¯ liá»‡u? Cross-validation (K-fold). Thá»±c hÃ nh vá»›i train_test_split(), KFold().",
                 icon="ğŸ“‘",
                 color='#e8f5e9'
                 )
            card("BÃ i 7: ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh",
                 "Regression: MAE, RMSE, RÂ². Classification: Accuracy, Precision, Recall, F1-score, ROC-AUC, Confusion Matrix.",
                 icon="ğŸ“‘",
                 color='#e8f5e9'
                 )
            card("BÃ i 8: Preprocessing cho ML",
                 "Chuáº©n hÃ³a dá»¯ liá»‡u vá»›i StandardScaler, MinMaxScaler. Encoding categorical vá»›i LabelEncoder, OneHotEncoder.",
                 icon="ğŸ“‘",
                 color='#e8f5e9'
                 )

        card("Mini Project 1: Dá»± Ä‘oÃ¡n giÃ¡ nhÃ ",
             "Dataset Boston Housing: EDA, preprocessing, Linear Regression, Ä‘Ã¡nh giÃ¡ vá»›i RMSE/RÂ², visualize predicted vs actual.",
             icon="ğŸ“‹",
             color='linear-gradient(135deg, #fbc2eb, #a6c1ee)'
             )

        card("Mini Project 2: PhÃ¢n loáº¡i khÃ¡ch hÃ ng",
             "Dataset Titanic: EDA, feature engineering, Logistic Regression, Ä‘Ã¡nh giÃ¡ báº±ng Confusion Matrix, ROC curve.",
             icon="ğŸ“‹",
             color='linear-gradient(135deg, #fbc2eb, #a6c1ee)'
             )

    # ================== CHÆ¯Æ NG 2 ==================
    st.markdown("---")
    st.header("ğŸ¯ ChÆ°Æ¡ng 2: Supervised Learning - Thuáº­t ToÃ¡n NÃ¢ng Cao")
    st.info("ğŸ¯ Má»¥c tiÃªu: LÃ m chá»§ cÃ¡c thuáº­t toÃ¡n ML quan trá»ng, hiá»ƒu Æ°u nhÆ°á»£c Ä‘iá»ƒm vÃ  cÃ¡ch Ã¡p dá»¥ng thá»±c táº¿")

    with st.expander("Xem chi tiáº¿t:"):
        col1, _, col2 = st.columns([8, 1, 8])

        with col1:
            card("BÃ i 1: Há»“i quy báº­c cao (Polynomial Regression)",
                 "Má»Ÿ rá»™ng Linear Regression vá»›i PolynomialFeatures. Bias-Variance tradeoff. TÃ¬m degree tá»‘i Æ°u báº±ng validation curve.",
                 icon="ğŸ“‘",
                 color='#e8f5e9'
                 )
            card("BÃ i 2: Decision Tree - Thuáº­t toÃ¡n chia nhÃ¡nh",
                 "CÃ¡ch tree 'quyáº¿t Ä‘á»‹nh' báº±ng Gini Impurity, Information Gain. Hyperparameters: max_depth, min_samples_split. Visualize tree.",
                 icon="ğŸ“‘",
                 color='#e8f5e9'
                 )
            card("BÃ i 3: Random Forest - Sá»©c máº¡nh táº­p thá»ƒ",
                 "Ensemble cá»§a nhiá»u Decision Tree. Bootstrap Aggregating (Bagging). Feature importance, Out-of-bag score.",
                 icon="ğŸ“‘",
                 color='#e8f5e9'
                 )
            card("BÃ i 4: Support Vector Machine (SVM)",
                 "TÃ¬m 'Ä‘Æ°á»ng biÃªn tá»‘t nháº¥t' (optimal hyperplane). Kernel trick: linear, polynomial, RBF. C parameter vÃ  gamma.",
                 icon="ğŸ“‘",
                 color='#e8f5e9'
                 )

        with col2:
            card("BÃ i 5: Naive Bayes - XÃ¡c suáº¥t Ä‘Æ¡n giáº£n",
                 "Bayes' theorem trong ML. GaussianNB, MultinomialNB. á»¨ng dá»¥ng: phÃ¢n loáº¡i email spam, sentiment analysis.",
                 icon="ğŸ“‘",
                 color='#e8f5e9'
                 )
            card("BÃ i 6: K-Nearest Neighbors (KNN)",
                 "Thuáº­t toÃ¡n 'hÃ ng xÃ³m gáº§n nháº¥t'. Chá»n k tá»‘i Æ°u, distance metrics (Euclidean, Manhattan). Lazy learning.",
                 icon="ğŸ“‘",
                 color='#e8f5e9'
                 )
            card("BÃ i 7: Overfitting & Regularization",
                 "Nháº­n biáº¿t overfitting qua learning curve. L1 (Lasso), L2 (Ridge) regularization. Dropout trong Neural Networks.",
                 icon="ğŸ“‘",
                 color='#e8f5e9'
                 )
            card("BÃ i 8: Hyperparameter Tuning",
                 "Grid Search vs Random Search vs Bayesian Optimization. Cross-validation cho tuning. Pipeline trong scikit-learn.",
                 icon="ğŸ“‘",
                 color='#e8f5e9'
                 )

        # Mini Projects
        card("Project 1: So sÃ¡nh thuáº­t toÃ¡n",
             "Dataset Iris: thá»­ nghiá»‡m Decision Tree, Random Forest, SVM, KNN trÃªn cÃ¹ng dataset. So sÃ¡nh accuracy, training time, interpretability.",
             icon="ğŸ“‹",
             color='linear-gradient(135deg, #fbc2eb, #a6c1ee)'
             )

        card("Project 2: PhÃ¢n loáº¡i email spam",
             "Dataset email: text preprocessing, TF-IDF, so sÃ¡nh Naive Bayes vs SVM. ÄÃ¡nh giÃ¡ vá»›i Precision/Recall vÃ¬ class imbalance.",
             icon="ğŸ“‹",
             color='linear-gradient(135deg, #fbc2eb, #a6c1ee)'
             )

    # ================== CHÆ¯Æ NG 3 ==================
    st.markdown("---")
    st.header("ğŸ” ChÆ°Æ¡ng 3: Unsupervised Learning")
    st.info("ğŸ¯ Má»¥c tiÃªu: KhÃ¡m phÃ¡ dá»¯ liá»‡u khÃ´ng nhÃ£n, phÃ¢n cá»¥m khÃ¡ch hÃ ng, giáº£m chiá»u dá»¯ liá»‡u vÃ  nÃ©n thÃ´ng tin")

    with st.expander("Xem chi tiáº¿t:"):
        col1, _, col2 = st.columns([8, 1, 8])

        with col1:
            card("BÃ i 1: Giá»›i thiá»‡u Unsupervised Learning",
                 "BÃ i toÃ¡n khÃ´ng cÃ³ 'Ä‘Ã¡p Ã¡n'. á»¨ng dá»¥ng: customer segmentation, anomaly detection, data compression. So sÃ¡nh vá»›i Supervised Learning.",
                 icon="ğŸ“‘",
                 color='#e8f5e9'
                 )
            card("BÃ i 2: K-Means Clustering",
                 "Thuáº­t toÃ¡n phÃ¢n cá»¥m phá»• biáº¿n nháº¥t. Centroids, inertia, elbow method Ä‘á»ƒ chá»n k. Æ¯u nhÆ°á»£c Ä‘iá»ƒm, assumption vá» cluster shape.",
                 icon="ğŸ“‘",
                 color='#e8f5e9'
                 )
            card("BÃ i 3: DBSCAN - PhÃ¢n cá»¥m dá»±a trÃªn máº­t Ä‘á»™",
                 "TÃ¬m cluster cÃ³ hÃ¬nh dáº¡ng báº¥t ká»³. Parameters: eps, min_samples. Xá»­ lÃ½ noise points. So sÃ¡nh vá»›i K-Means.",
                 icon="ğŸ“‘",
                 color='#e8f5e9'
                 )
            card("BÃ i 4: Hierarchical Clustering",
                 "Agglomerative vs Divisive. Dendrogram Ä‘á»ƒ visualize. Linkage criteria: single, complete, average, ward.",
                 icon="ğŸ“‘",
                 color='#e8f5e9'
                 )

        with col2:
            card("BÃ i 5: Principal Component Analysis (PCA)",
                 "Giáº£m chiá»u dá»¯ liá»‡u báº±ng cÃ¡ch tÃ¬m 'hÆ°á»›ng quan trá»ng nháº¥t'. Eigenvalues, Eigenvectors. Explained variance ratio.",
                 icon="ğŸ“‘",
                 color='#e8f5e9'
                 )
            card("BÃ i 6: t-SNE - Visualization Ä‘a chiá»u",
                 "Giáº£m chiá»u cho visualization. Perplexity parameter. So sÃ¡nh vá»›i PCA: linear vs non-linear dimensionality reduction.",
                 icon="ğŸ“‘",
                 color='#e8f5e9'
                 )
            card("BÃ i 7: Autoencoder - MÃ´ hÃ¬nh nÃ©n dá»¯ liá»‡u",
                 "Neural Network há»c cÃ¡ch 'nÃ©n' vÃ  'giáº£i nÃ©n' dá»¯ liá»‡u. Encoder-Decoder architecture. á»¨ng dá»¥ng: denoising, anomaly detection.",
                 icon="ğŸ“‘",
                 color='#e8f5e9'
                 )
            card("BÃ i 8: Anomaly Detection",
                 "PhÃ¡t hiá»‡n dá»¯ liá»‡u 'báº¥t thÆ°á»ng'. Isolation Forest, One-Class SVM. á»¨ng dá»¥ng: fraud detection, system monitoring.",
                 icon="ğŸ“‘",
                 color='#e8f5e9'
                 )

        # Projects
        card("Project 1: Customer Segmentation",
             "Dataset khÃ¡ch hÃ ng: RFM analysis, K-Means clustering, PCA visualization, profile tá»«ng segment, business insights.",
             icon="ğŸ“‹",
             color='linear-gradient(135deg, #fbc2eb, #a6c1ee)'
             )

        card("Project 2: PhÃ¢n tÃ­ch sáº£n pháº©m",
             "Dataset sáº£n pháº©m e-commerce: clustering sáº£n pháº©m tÆ°Æ¡ng tá»±, PCA giáº£m chiá»u features, t-SNE visualization, recommendation system Ä‘Æ¡n giáº£n.",
             icon="ğŸ“‹",
             color='linear-gradient(135deg, #fbc2eb, #a6c1ee)'
             )

    # ================== CHÆ¯Æ NG 4: ENSEMBLE & ADVANCED ==================
    st.markdown("---")
    st.header("âš¡ ChÆ°Æ¡ng 4: Ensemble Methods & Advanced Techniques")
    st.info("ğŸ¯ Má»¥c tiÃªu: NÃ¢ng cao hiá»‡u suáº¥t mÃ´ hÃ¬nh vá»›i Ensemble, lÃ m chá»§ XGBoost vÃ  cÃ¡c ká»¹ thuáº­t ML nÃ¢ng cao")

    with st.expander("Xem chi tiáº¿t:"):
        col1, _, col2 = st.columns([8, 1, 8])

        with col1:
            card("BÃ i 1: Ensemble Learning Overview",
                 "Wisdom of crowds trong ML. Bagging vs Boosting vs Stacking. Bias-Variance tradeoff trong ensemble.",
                 icon="ğŸ“‘",
                 color='#e8f5e9'
                 )
            card("BÃ i 2: Bagging & Extra Trees",
                 "Random Forest chi tiáº¿t hÆ¡n. ExtraTreesClassifier. Out-of-bag evaluation. Parallel processing trong ensemble.",
                 icon="ğŸ“‘",
                 color='#e8f5e9'
                 )
            card("BÃ i 3: Boosting - AdaBoost & Gradient Boosting",
                 "Sequential learning: há»c tá»« lá»—i cá»§a mÃ´ hÃ¬nh trÆ°á»›c. AdaBoost, GradientBoostingClassifier. Learning rate vÃ  n_estimators.",
                 icon="ğŸ“‘",
                 color='#e8f5e9'
                 )

        with col2:
            card("BÃ i 4: XGBoost - Extreme Gradient Boosting",
                 "Thuáº­t toÃ¡n 'vua' cá»§a competitions. Hyperparameters quan trá»ng: max_depth, learning_rate, subsample. Early stopping.",
                 icon="ğŸ“‘",
                 color='#e8f5e9'
                 )
            card("BÃ i 5: LightGBM & CatBoost",
                 "Alternatives cho XGBoost. LightGBM: tá»‘c Ä‘á»™ cao. CatBoost: xá»­ lÃ½ categorical tá»± Ä‘á»™ng. So sÃ¡nh performance.",
                 icon="ğŸ“‘",
                 color='#e8f5e9'
                 )
            card("BÃ i 6: Stacking & Blending",
                 "Meta-learning: train mÃ´ hÃ¬nh trÃªn predictions cá»§a cÃ¡c mÃ´ hÃ¬nh khÃ¡c. StackingClassifier trong scikit-learn.",
                 icon="ğŸ“‘",
                 color='#e8f5e9'
                 )

        # Advanced Project
        card("Competition Project: Kaggle-Style Challenge",
             "Dataset thi Ä‘áº¥u: feature engineering nÃ¢ng cao, ensemble nhiá»u mÃ´ hÃ¬nh (RF + XGBoost + LightGBM), stacking, hyperparameter tuning, leaderboard simulation.",
             icon="ğŸ“‹",
             color='linear-gradient(135deg, #fbc2eb, #a6c1ee)'
             )

    # ================== CHÆ¯Æ NG 5: MODEL DEPLOYMENT ==================
    st.markdown("---")
    st.header("ğŸš€ ChÆ°Æ¡ng 5: Model Deployment & MLOps")
    st.info("ğŸ¯ Má»¥c tiÃªu: Triá»ƒn khai mÃ´ hÃ¬nh thá»±c táº¿, monitor performance, versioning vÃ  CI/CD cho ML")

    with st.expander("Xem chi tiáº¿t:"):
        col1, _, col2 = st.columns([8, 1, 8])

        with col1:
            card("BÃ i 1: Model Serialization",
                 "LÆ°u mÃ´ hÃ¬nh vá»›i pickle, joblib. Model versioning. LÆ°u preprocessing pipeline cÃ¹ng vá»›i model.",
                 icon="ğŸ“‘",
                 color='#e8f5e9'
                 )
            card("BÃ i 2: Web API vá»›i FastAPI/Flask",
                 "Táº¡o REST API cho model prediction. JSON input/output. Error handling vÃ  validation. Docker containerization.",
                 icon="ğŸ“‘",
                 color='#e8f5e9'
                 )
            card("BÃ i 3: Streamlit Web App",
                 "Táº¡o demo app nhanh chÃ³ng. File upload, real-time prediction, visualization. Deploy lÃªn Streamlit Cloud.",
                 icon="ğŸ“‘",
                 color='#e8f5e9'
                 )

        with col2:
            card("BÃ i 4: Model Monitoring",
                 "Data drift, model drift detection. Performance monitoring in production. Alerting system.",
                 icon="ğŸ“‘",
                 color='#e8f5e9'
                 )
            card("BÃ i 5: A/B Testing cho ML",
                 "Thá»­ nghiá»‡m mÃ´ hÃ¬nh má»›i vs cÅ©. Statistical significance. Multi-armed bandit approach.",
                 icon="ğŸ“‘",
                 color='#e8f5e9'
                 )
            card("BÃ i 6: CI/CD Pipeline",
                 "Automated testing cho ML code. Model validation pipeline. GitHub Actions cho ML deployment.",
                 icon="ğŸ“‘",
                 color='#e8f5e9'
                 )

        # Final Project
        card("Capstone Project: End-to-End ML System",
             "XÃ¢y dá»±ng há»‡ thá»‘ng ML hoÃ n chá»‰nh: tá»« data pipeline, feature engineering, model training, API deployment, monitoring dashboard, A/B testing setup.",
             icon="ğŸ“‹",
             color='linear-gradient(135deg, #fbc2eb, #a6c1ee)'
             )

    st.markdown("---")
    st.success("ğŸ‘‰ HoÃ n thÃ nh Machine Learning track, báº¡n sáº½ cÃ³ kiáº¿n thá»©c vá»¯ng vá» cÃ¡c thuáº­t toÃ¡n ML, biáº¿t deploy model production vÃ  xÃ¢y dá»±ng end-to-end ML system!")